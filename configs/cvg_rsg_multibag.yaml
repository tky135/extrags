seed: 0
dataset: multibag/7cams

# ------------- Trainer ------------ #
trainer:
  type: models.trainers.MultiTrainer
  ground_method: neus # [neus, rsg]
  n_camera: 7
  export_neus_2dgs: True
  optim:
    num_iters: 60000
    lidar_pretrain_iters: 0
    use_grad_scaler: false
    cache_buffer_freq: -1 # we use error based image sampler for training with more than 3 cameras
  render:
    near_plane: 0.1 # near plane for rendering
    far_plane: 10000000000.0 # far plane for rendering
    antialiased: false # whether to use antialiasing for gaussian rendering, supported by gsplat kernel
    packed: false # whether to use packed rendering, supported by gsplat kernel
    absgrad: true # whether to use absolute gradient for rendering, supported by gsplat kernel
    sparse_grad: false # whether to use sparse gradient for rendering, supported by gsplat kernel
    batch_size: 1 # batch size for rendering, currently only support 1
  losses:
    rgb:
      w: 0.8
    ssim:
      w: 0.2
    mask:
      w: 0.5
      opacity_loss_type: bce # choose from [bce, safe_bce]
    normal_consistency:
      w: 1.0
    distortion:
      w: 1.0
    align_error:
      w: 1e2
    # depth:
    #   w: 0.01 # weight of depth loss
    #   inverse_depth: False # whether to use inverse depth, NOTE that when set to True, must normalize=True
    #   normalize: False # whether to normalize depth loss
    #   loss_type: l1 # choose from ["l1", "l2"]
    affine:
      w: 0.00001 # weight of affine regularization
    ground_gs_sdf:
      w: 0.1
  res_schedule:
    double_steps: 250 # training starts at 1/d resolution, every n steps this is doubled
    downscale_times: 2 # at the beginning, resolution is 1/2^d, where d is this number
  gaussian_optim_general_cfg:
    xyz:
      lr: 1.6e-04
      lr_final: 1.6e-06
      scale_factor: scene_radius # str or float, if "scene_scale", scale the learning rate by the scene scale
    sh_dc:
      lr: 0.0025
    sh_rest:
      lr: 0.000125
    opacity:
      lr: 0.05
    scaling:
      lr: 0.005
    rotation:
      lr: 0.001
  gaussian_ctrl_general_cfg:
    warmup_steps: 10000             # warmup steps for alpha
    reset_alpha_interval: 9000    # reset alpha every n steps
    refine_interval: 300          # refine gaussians every n steps
    sh_degree_interval: 1000      # every n intervals turn on another sh degree
    n_split_samples: 2            # number of samples to split gaussians into
    # may differ in different models
    reset_alpha_value: 0.01       # reset alpha to this value
    densify_grad_thresh: 0.0005   # above this grad, gaussians are densified
    densify_size_thresh: 0.003    # below this size, gaussians are *duplicated*, otherwise split
    cull_alpha_thresh: 0.005      # threshold of opacity for culling gaussians
    cull_scale_thresh: 0.5        # threshold of scale for culling gaussians
    cull_screen_size: 0.15        # if a gaussian is more than this percent of screen space, cull it
    split_screen_size: 0.05       # if a gaussian is more than this percent of screen space, split it
    stop_screen_size_at: 10000     # stop culling/splitting at this step WRT screen size of gaussians
    stop_split_at: 45000          # stop splitting at this step
    sh_degree: 3                  # sh degree for gaussians

# ------------- Model ------------ #
model:
  Background:
    type: models.gaussians.VanillaGaussians
    init:
      from_lidar:
        num_samples: 3000_000
        return_color: True
      near_randoms: 100_000
      far_randoms: 100_000
    reg:
      sharp_shape_reg:
        w: 1.
        step_interval: 10
        max_gauss_ratio: 10.       # threshold of ratio of gaussian max to min scale before applying regularization loss from the PhysGaussian paper
  Ground_gs:
    type: models.gaussians.VanillaGaussians
    gaussian_2d: True
    ground_gs: True
    sdf_grad: False
    clip_scale: 0.1
    reg:
      sharp_shape_reg:
        w: 1.
        step_interval: 10
        max_gauss_ratio: 5.
      # sparse_reg:
      #   w: 0.1
      #   start_step: 10000
      max_s_square_reg:
        w: 0.1
    optim:
      xyz:
        lr: 6.4e-04
        lr_final: 1.6e-06
        scale_factor: 10.0
    ctrl:
      densify_grad_thresh: 0.00005
      cull_alpha_thresh: 0.005
      sh_degree: 3
      sh_degree_interval: 10000
  CameraEncod:
    type: models.modules.CameraEncodwBag
    params:
      n_camera: 7
    optim:
      all:
        lr: 5.0e-5
        weight_decay: 1.0e-6
  Ground:
    type: models.modules.Ground
    pretrain_method: egopose # [egopose, lidar]
    pretrain_iters: 10000
    params:
      batch_size: 8192
      resolution: 1024
      losses: 
        l1:
          w: 1.
        eikonal:
          w: 0.162
        s_val:
          w: 1.
        delta_color:
          w: 0.05
    optim:
      all:
        lr: 5.0e-4
  Sky:
    type: models.modules.EnvLight
    params:
      resolution: 1024
    optim:
      all:
        lr: 0.01
  # Affine:
  #   type: models.modules.AffineTransform
  #   params:
  #     embedding_dim: 4
  #     base_mlp_layer_width: 64
  #     pixel_affine: False
  #   optim:
  #     all:
  #       lr: 1.0e-5
  #       weight_decay: 1.0e-6
  CamPose:
    type: models.modules.CameraOptModule
    optim:
      all:
        lr: 1.0e-5
        weight_decay: 1.0e-6
# ------------- render ------------ #
render:
  fps: 10 # frames per second for the main rendered output
  render_full: True # whether to render full resolution videos
  render_test: True # whether to render test set
  render_novel: 
    traj_types:
      # - front_center_interp # type of trajectory for novel view synthesis
      # - s_curve
      # - three_key_poses
      # - x_shift_left
      # - y_shift_left
      - y_shift_right_ff
      - y_shift_right
      - y_shift_right_fr
      - y_shift_right_fl
      - y_shift_right_rl
      - y_shift_right_rr
      - y_shift_right_rm
    fps: 24 # frames per second for novel view rendering
  vis_lidar: False # whether to visualize lidar points on ground truth images
  vis_sky: False # whether to include "rgb_sky" and "rgb_sky_blend" in rendered keys
  vis_error: False # whether to include "rgb_error_map" in rendered keys

# ------------- logging ------------ #
logging:
  vis_freq: 2000 # how often to visualize training stats
  print_freq: 500 # how often to print training stats
  saveckpt_freq: 15000 # how often to save checkpoints
  save_seperate_video: True # whether to save seperate videos for each scene